{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e465a4bc-00c9-40ef-8662-fd5873684b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler saved successfully!\n",
      "Epoch 1/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0741 - loss: 3.2407 - val_accuracy: 0.1190 - val_loss: 3.1777\n",
      "Epoch 2/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1542 - loss: 3.1180 - val_accuracy: 0.1905 - val_loss: 2.9869\n",
      "Epoch 3/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1735 - loss: 2.8883 - val_accuracy: 0.2083 - val_loss: 2.6674\n",
      "Epoch 4/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2443 - loss: 2.5019 - val_accuracy: 0.2679 - val_loss: 2.2887\n",
      "Epoch 5/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3248 - loss: 2.1494 - val_accuracy: 0.3869 - val_loss: 1.9464\n",
      "Epoch 6/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4066 - loss: 1.8669 - val_accuracy: 0.3810 - val_loss: 1.7637\n",
      "Epoch 7/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4442 - loss: 1.6607 - val_accuracy: 0.3929 - val_loss: 1.7430\n",
      "Epoch 8/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4316 - loss: 1.5429 - val_accuracy: 0.4286 - val_loss: 1.5411\n",
      "Epoch 9/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5130 - loss: 1.4191 - val_accuracy: 0.4881 - val_loss: 1.4049\n",
      "Epoch 10/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5099 - loss: 1.3100 - val_accuracy: 0.5893 - val_loss: 1.2953\n",
      "Epoch 11/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5576 - loss: 1.2664 - val_accuracy: 0.5774 - val_loss: 1.2759\n",
      "Epoch 12/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5929 - loss: 1.1869 - val_accuracy: 0.5595 - val_loss: 1.2253\n",
      "Epoch 13/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6376 - loss: 1.0742 - val_accuracy: 0.6310 - val_loss: 1.1667\n",
      "Epoch 14/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5894 - loss: 1.0852 - val_accuracy: 0.6845 - val_loss: 1.0500\n",
      "Epoch 15/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6779 - loss: 0.9523 - val_accuracy: 0.6488 - val_loss: 1.0850\n",
      "Epoch 16/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6439 - loss: 0.9422 - val_accuracy: 0.6131 - val_loss: 1.0876\n",
      "Epoch 17/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6716 - loss: 0.9371 - val_accuracy: 0.7262 - val_loss: 0.9862\n",
      "Epoch 18/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6577 - loss: 0.9281 - val_accuracy: 0.7024 - val_loss: 0.9211\n",
      "Epoch 19/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6924 - loss: 0.8395 - val_accuracy: 0.7738 - val_loss: 0.8830\n",
      "Epoch 20/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7223 - loss: 0.7768 - val_accuracy: 0.7738 - val_loss: 0.9024\n",
      "Epoch 21/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7541 - loss: 0.7443 - val_accuracy: 0.7440 - val_loss: 0.8562\n",
      "Epoch 22/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7329 - loss: 0.7556 - val_accuracy: 0.7738 - val_loss: 0.8231\n",
      "Epoch 23/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7582 - loss: 0.7191 - val_accuracy: 0.6964 - val_loss: 0.8507\n",
      "Epoch 24/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7261 - loss: 0.6992 - val_accuracy: 0.8036 - val_loss: 0.7890\n",
      "Epoch 25/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7910 - loss: 0.6696 - val_accuracy: 0.7143 - val_loss: 0.8600\n",
      "Epoch 26/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7115 - loss: 0.7702 - val_accuracy: 0.7500 - val_loss: 0.7880\n",
      "Epoch 27/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7473 - loss: 0.7030 - val_accuracy: 0.7857 - val_loss: 0.7563\n",
      "Epoch 28/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7919 - loss: 0.5949 - val_accuracy: 0.8095 - val_loss: 0.8030\n",
      "Epoch 29/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7933 - loss: 0.6451 - val_accuracy: 0.7917 - val_loss: 0.7147\n",
      "Epoch 30/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7571 - loss: 0.6205 - val_accuracy: 0.6964 - val_loss: 0.7983\n",
      "Epoch 31/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7784 - loss: 0.5915 - val_accuracy: 0.6131 - val_loss: 1.0072\n",
      "Epoch 32/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7599 - loss: 0.6152 - val_accuracy: 0.8036 - val_loss: 0.7141\n",
      "Epoch 33/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7887 - loss: 0.5536 - val_accuracy: 0.8155 - val_loss: 0.8091\n",
      "Epoch 34/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8047 - loss: 0.5323 - val_accuracy: 0.8036 - val_loss: 0.7054\n",
      "Epoch 35/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8023 - loss: 0.5579 - val_accuracy: 0.7917 - val_loss: 0.7078\n",
      "Epoch 36/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8049 - loss: 0.5285 - val_accuracy: 0.7917 - val_loss: 0.6950\n",
      "Epoch 37/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8090 - loss: 0.5173 - val_accuracy: 0.7143 - val_loss: 0.8746\n",
      "Epoch 38/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8231 - loss: 0.4857 - val_accuracy: 0.8155 - val_loss: 0.6759\n",
      "Epoch 39/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8580 - loss: 0.4488 - val_accuracy: 0.7976 - val_loss: 0.7109\n",
      "Epoch 40/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8220 - loss: 0.4840 - val_accuracy: 0.8155 - val_loss: 0.7211\n",
      "Epoch 41/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7880 - loss: 0.5319 - val_accuracy: 0.7976 - val_loss: 0.6653\n",
      "Epoch 42/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8407 - loss: 0.4618 - val_accuracy: 0.8036 - val_loss: 0.6841\n",
      "Epoch 43/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8348 - loss: 0.4617 - val_accuracy: 0.8274 - val_loss: 0.6520\n",
      "Epoch 44/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8691 - loss: 0.3840 - val_accuracy: 0.8155 - val_loss: 0.6325\n",
      "Epoch 45/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8606 - loss: 0.4029 - val_accuracy: 0.7857 - val_loss: 0.6970\n",
      "Epoch 46/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8332 - loss: 0.4191 - val_accuracy: 0.8036 - val_loss: 0.6891\n",
      "Epoch 47/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8257 - loss: 0.4618 - val_accuracy: 0.7202 - val_loss: 0.7647\n",
      "Epoch 48/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8609 - loss: 0.3833 - val_accuracy: 0.8333 - val_loss: 0.6252\n",
      "Epoch 49/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8489 - loss: 0.3705 - val_accuracy: 0.7917 - val_loss: 0.7095\n",
      "Epoch 50/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8409 - loss: 0.4141 - val_accuracy: 0.8333 - val_loss: 0.6238\n",
      "Epoch 51/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8562 - loss: 0.3994 - val_accuracy: 0.8452 - val_loss: 0.6156\n",
      "Epoch 52/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8875 - loss: 0.3445 - val_accuracy: 0.8214 - val_loss: 0.6786\n",
      "Epoch 53/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8849 - loss: 0.3675 - val_accuracy: 0.8452 - val_loss: 0.6284\n",
      "Epoch 54/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8578 - loss: 0.3719 - val_accuracy: 0.8631 - val_loss: 0.6302\n",
      "Epoch 55/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8548 - loss: 0.3825 - val_accuracy: 0.8214 - val_loss: 0.7033\n",
      "Epoch 56/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8945 - loss: 0.3410 - val_accuracy: 0.8036 - val_loss: 0.6703\n",
      "Epoch 57/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8359 - loss: 0.4183 - val_accuracy: 0.8452 - val_loss: 0.6330\n",
      "Epoch 58/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8835 - loss: 0.3449 - val_accuracy: 0.8571 - val_loss: 0.5939\n",
      "Epoch 59/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8848 - loss: 0.3181 - val_accuracy: 0.7976 - val_loss: 0.7037\n",
      "Epoch 60/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8529 - loss: 0.3775 - val_accuracy: 0.8452 - val_loss: 0.6903\n",
      "Epoch 61/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8804 - loss: 0.3290 - val_accuracy: 0.8512 - val_loss: 0.6420\n",
      "Epoch 62/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8951 - loss: 0.3518 - val_accuracy: 0.8631 - val_loss: 0.6259\n",
      "Epoch 63/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9094 - loss: 0.2910 - val_accuracy: 0.8452 - val_loss: 0.6684\n",
      "Epoch 64/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8657 - loss: 0.3263 - val_accuracy: 0.8750 - val_loss: 0.6416\n",
      "Epoch 65/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9042 - loss: 0.2930 - val_accuracy: 0.8571 - val_loss: 0.6378\n",
      "Epoch 66/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8955 - loss: 0.2899 - val_accuracy: 0.8155 - val_loss: 0.6636\n",
      "Epoch 67/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8385 - loss: 0.3528 - val_accuracy: 0.8690 - val_loss: 0.6069\n",
      "Epoch 68/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8843 - loss: 0.3259 - val_accuracy: 0.8452 - val_loss: 0.6578\n",
      "Epoch 69/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9038 - loss: 0.2870 - val_accuracy: 0.8571 - val_loss: 0.6174\n",
      "Epoch 70/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9026 - loss: 0.3028 - val_accuracy: 0.8690 - val_loss: 0.6209\n",
      "Epoch 71/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9100 - loss: 0.2461 - val_accuracy: 0.8333 - val_loss: 0.7226\n",
      "Epoch 72/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8824 - loss: 0.2955 - val_accuracy: 0.8571 - val_loss: 0.6392\n",
      "Epoch 73/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9079 - loss: 0.2566 - val_accuracy: 0.8750 - val_loss: 0.6242\n",
      "Epoch 74/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9204 - loss: 0.2576 - val_accuracy: 0.7738 - val_loss: 0.7988\n",
      "Epoch 75/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8748 - loss: 0.3046 - val_accuracy: 0.8869 - val_loss: 0.6106\n",
      "Epoch 76/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9220 - loss: 0.2246 - val_accuracy: 0.8750 - val_loss: 0.6607\n",
      "Epoch 77/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9117 - loss: 0.2629 - val_accuracy: 0.8929 - val_loss: 0.5893\n",
      "Epoch 78/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9056 - loss: 0.2492 - val_accuracy: 0.8512 - val_loss: 0.7202\n",
      "Epoch 79/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9142 - loss: 0.2537 - val_accuracy: 0.8869 - val_loss: 0.6154\n",
      "Epoch 80/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9039 - loss: 0.2579 - val_accuracy: 0.8393 - val_loss: 0.6455\n",
      "Epoch 81/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9171 - loss: 0.2669 - val_accuracy: 0.8869 - val_loss: 0.6449\n",
      "Epoch 82/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9246 - loss: 0.2275 - val_accuracy: 0.8869 - val_loss: 0.6402\n",
      "Epoch 83/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8909 - loss: 0.2922 - val_accuracy: 0.8869 - val_loss: 0.6179\n",
      "Epoch 84/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9384 - loss: 0.1983 - val_accuracy: 0.8095 - val_loss: 0.7799\n",
      "Epoch 85/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8828 - loss: 0.2900 - val_accuracy: 0.8869 - val_loss: 0.6146\n",
      "Epoch 86/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9108 - loss: 0.2575 - val_accuracy: 0.9048 - val_loss: 0.6272\n",
      "Epoch 87/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9395 - loss: 0.1992 - val_accuracy: 0.8929 - val_loss: 0.6385\n",
      "Epoch 88/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9348 - loss: 0.2041 - val_accuracy: 0.8512 - val_loss: 0.6999\n",
      "Epoch 89/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9213 - loss: 0.2052 - val_accuracy: 0.8869 - val_loss: 0.6566\n",
      "Epoch 90/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9291 - loss: 0.2195 - val_accuracy: 0.8810 - val_loss: 0.6588\n",
      "Epoch 91/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8894 - loss: 0.2774 - val_accuracy: 0.8512 - val_loss: 0.7170\n",
      "Epoch 92/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9032 - loss: 0.2650 - val_accuracy: 0.8571 - val_loss: 0.6491\n",
      "Epoch 93/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9410 - loss: 0.1976 - val_accuracy: 0.8571 - val_loss: 0.6393\n",
      "Epoch 94/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9220 - loss: 0.2518 - val_accuracy: 0.8690 - val_loss: 0.6648\n",
      "Epoch 95/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9260 - loss: 0.2313 - val_accuracy: 0.8869 - val_loss: 0.6563\n",
      "Epoch 96/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9320 - loss: 0.2064 - val_accuracy: 0.8631 - val_loss: 0.6670\n",
      "Epoch 97/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9420 - loss: 0.1704 - val_accuracy: 0.8750 - val_loss: 0.6826\n",
      "Epoch 98/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9487 - loss: 0.1823 - val_accuracy: 0.8810 - val_loss: 0.6562\n",
      "Epoch 99/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9467 - loss: 0.1918 - val_accuracy: 0.9107 - val_loss: 0.6313\n",
      "Epoch 100/100\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9419 - loss: 0.1737 - val_accuracy: 0.8810 - val_loss: 0.6666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Model trained and saved successfully!\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8943 - loss: 0.5295  \n",
      "Test Accuracy: 88.10%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import pickle\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"asl_dataset.csv\")\n",
    "\n",
    "# Separate features (landmarks) and labels\n",
    "X = df.drop(columns=['label']).values\n",
    "y = df['label'].values\n",
    "\n",
    "# Normalize landmark data (Scale between 0 and 1)\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)  # Apply normalization\n",
    "\n",
    "# Save the scaler for real-time prediction\n",
    "with open(\"scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"Scaler saved successfully!\")\n",
    "\n",
    "# Encode labels (convert letters to numbers)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Save label encoder for real-time usage\n",
    "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "# Split dataset (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert labels to categorical (one-hot encoding for softmax)\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=len(label_encoder.classes_))\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=len(label_encoder.classes_))\n",
    "\n",
    "# Define a deeper neural network model with reduced dropout\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(42,)),  # 21 hand landmarks (x, y)\n",
    "    keras.layers.Dense(512, activation=\"relu\"),  # Increased neurons\n",
    "    keras.layers.Dropout(0.1),  # Reduced dropout\n",
    "    keras.layers.Dense(256, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(len(label_encoder.classes_), activation=\"softmax\")  # Output layer\n",
    "])\n",
    "\n",
    "# Use a lower learning rate\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0005)  # Reduced from default 0.001\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"asl_mlp_model.h5\")\n",
    "\n",
    "print(\"MLP Model trained and saved successfully!\")\n",
    "\n",
    "# Load trained model\n",
    "model = keras.models.load_model(\"asl_mlp_model.h5\")\n",
    "\n",
    "# Evaluate on test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
